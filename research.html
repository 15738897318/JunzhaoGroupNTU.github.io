<!DOCTYPE html>
<html lang="en">
<!-- InstanceBegin template="/Templates/common_page.dwt" codeOutsideHTMLIsLocked="false" -->

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0,maximum-scale=1">
    <!-- InstanceBeginEditable name="doctitle" -->
    <title>News and Teaching</title>
    <!-- InstanceEndEditable -->
    <!-- Loading third party fonts -->
    <link href="fonts/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!-- Loading main css file -->
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/style_slide.css">
    <!--[if lt IE 9]>
		<script src="js/ie-support/html5.js"></script>
		<script src="js/ie-support/respond.js"></script>
		<![endif]-->
    <!-- InstanceBeginEditable name="head" -->
    <!-- InstanceEndEditable -->
		<style type="text/css">
		table.ranking {
			text-align: left;
			border-radius: 5px;
			border: 1px solid #dde7ea;
		}
		table.ranking thead tr{
			background:#4472C4;
		}
		table.ranking tbody tr:nth-child(odd){
			background:#CFD5EA;
		}
		table.ranking tbody tr:nth-child(even){
			background:#E9EBF5;
		}
		table.ranking tr td:nth-child(1){
			background:#4472C4;
		}
	</style>
</head>

<body>
    <div class="site-content">
        <header class="site-header" data-bg-image="">
            <!-- InstanceBeginEditable name="NoEdit-1" -->
            <!-- InstanceEndEditable -->
            <div class="container">
                <div class="header-bar">
            
                    </a>
                    <nav class="main-navigation">
                        <!--<br>-->
                        <button class="menu-toggle">
                            <i class="fa fa-bars"></i>
                        </button>
                        <ul class="menu">
                            <!-- InstanceBeginEditable name="menu-item" -->
                            <li class="home menu-item">
                                <a href="index.html">
                                    <img src="images/home-icon.png" alt="Home"> HOME</a>
                            </li>
                            <li class="menu-item">
                                <a href="research.html">Research </a>
                            </li>
                            <li class="menu-item">
                                <a href="members.html">Team </a>
                            </li>
                            <li class="menu-item">
                                <a href="publications.html">Publications </a>
                            </li>
                            <li class="menu-item">
                                <a href="PapersToCite.html">Best Paper to Cite</a>
                              </li>
                            <li class="menu-item current-menu-item">
                                <a href="news.html">News</a>
                            </li>
                            <li class="menu-item">
                                <a href="joinus.html">Join The Team</a>
                            </li>
                            <li class="menu-item">
                                <a href="IEEE-stylebio.html">IEEE-stylebio</a>
                            </li>
                            <!-- InstanceEndEditable -->
                        </ul>
                    </nav>
                    <div class="mobile-navigation"></div>
                </div>
            </div>
        </header>
        <!-- InstanceBeginEditable name="page-title" -->
        <div class="page-head" data-bg-image="images/page-head-1.jpg">
            <div class="container">
                <h2 class="page-title">News</h2>
				 <small>News and Teaching Courses</small>
                <!-- InstanceEndEditable -->
            </div>
        </div>
        <main class="main-content">
      <div class="container">
	  </br>
        <!-- InstanceBeginEditable name="main-content" -->
        <div class="col-md-13">
<div class="col-md-13">
         
          <div class="boxed-news">
            <div class="content">
		  
		  <br>  
		   <h2 class="section-title">
           Research
          </h2>
  			 
                        
1. Artificial Intelligence (AI)
1.1 Autonomous Deep Learning ZZ
1.2 Computer Vision (CV)
1.3 ?
1.4 Adversarial Machine Learning
1.5 Reinforcement Learning
1.6 Federated Learning
2. City Brain / Smart Nation: Internet of Things (IoT), Cloud/Edge/Fog Computing
3. Security / Privacy
4. 6G Wireless Networks (including AI and Intelligent Reflecting Surfaces)

1. Artificial Intelligence (AI)

1.1 Autonomous Deep Learning for Continual Learning in Complex Data Stream Environment

Researcher: Andri Ashfahani

The goal of this research is to step-by-step solve complex data stream problems in continual learning environments using deep neural networks (DNNs). There are four articles in this research. Each of these articles presents a new method for data stream learning using DNN. Each of these articles demonstrates the effectiveness of the proposed method in the streaming environment. The proposed methods are applicable and in some cases have been applied to other kinds of tasks, i.e, transfer learning and control algorithms, but this research does not explore such applications.

1.1.1 Incremental Learning of Deep Neural Networks for Evolving Data Streams
In the first article, the problem of how to incrementally increase the network capacity in respect to problem complexity is handled. We proposed incremental learning of DNNs for Evolving Data Streams, namely Autonomous Deep Learning (ADL). It characterizes flexible network structure where its hidden nodes and hidden layers can be incrementally constructed from scratch. The network significance (NS) formula derived from bias-variance tradeoff is utilized to control the network complexity. This formula works by monitoring the possible underfitting and overfitting situation of a DNN. To further identify loss of generalization power, Drift detection scenario (DDS) is carried out to signal a real drift situation. This triggers the construction of a new hidden layer. The concept of different depth network structure is put forward to specifically combat the catastrophic forgetting problem because of hidden layer evolution. That is, ADL accommodates every hidden layer output in the final classification decision such that it is able to flexibly retain the constructed knowledge in the previous layers. The learning policy of ADL is depicted in Fig. 1. ADL succeeds at solving classification problems which is simulated under prequential test-then-train protocol. The different depth network structure of ADL, however, is only viable for classification problems and is not fully suitable for other implementation scenarios. Note that ADL is able to put different emphasis on every hidden layer based on the accuracy matrix. In the control system and regression problems, for instance, the accuracy matrix cannot be obtained as those problems usually employ mean squared error (MSE) loss as the objective function. It highlights the importance of Multi-layer Perceptron (MLP)-like network structure as it is more applicable in other scenarios.
 

Figure 1:The learning policy of ADL

Ashfahani, Andri, and Mahardhika Pratama. "Autonomous deep learning: Continual learning approach for dynamic environments." In Proceedings of the 2019 SIAM International Conference on Data Mining, pp. 666-674. Society for Industrial and Applied Mathematics, 2019.
1.1.2 Automatic Construction of Multi-layer Perceptron (MLP) from Streaming Examples 
In the second article, we explore the strategy to expand the capacity of MLP structure in respect to the problem complexity. We formalize this method as a Neural Network with Dynamically Evolved Capacity (NADINE). The main bottleneck to evolve a MLP structure is the loss of performance whenever a new hidden layer is added. We called this problem a catastrophic forgetting because of structural evolution. The major cause of this is the random initialization of the newly added layer. This problem is mitigated by using a sample and replay mechanism. It is understood that retaining samples and retraining the model should be avoided in the context of data stream learning. Because of that reason, a method to collect important samples, namely adaptive memory, from the streaming data is developed. The collected samples are then used to retrain the network whenever there is a real drift confirmed by DDS. It is worth mentioning that the size of the important samples can be maintained and the retraining process is only conducted whenever there is a new layer. Because every hidden layer is constructed in different concepts, it is important to govern the amount of updates in each hidden layer according to its relevance to the output. The soft-forgetting strategy is proposed to handle this objective where it translates the correlation of each hidden layer and output to independent learning raters for every hidden layer. Finally, the hidden node evolving mechanism utilizes the similar method introduced in ADL. The learning policy of NADINE is presented in Fig. 2, red box indicates the additional learning strategies compared to the previous article. NADINE is tested on both classification and regression problems where it is better than other benchmarks. ADL and NADINE, however, do not fully consider the fact that data come without labels because it has no unsupervised learning mechanism to handle concept drifts exploiting unlabeled samples.
 

Figure 2:The learning policy of NADINE

Pratama, Mahardhika, Choiru Za'in, Andri Ashfahani, Yew Soon Ong, and Weiping Ding. "Automatic construction of multi-layer perceptron network from streaming examples." In Proceedings of the 28th ACM International Conference on Information and Knowledge Management, pp. 1171-1180. 2019.
1.1.3 Incremental Learning of Denoising Autoencoder for Evolving Data Streams
In the third article, we revisit the concept of denoising autoencoders (DAE) as a generative training mechanism which addresses the random initialization problem of DNNs. From the viewpoint of continual learning in the streaming environment, it encourages DNNs to adapt to concept changes while waiting the labeling process. Being motivated by these facts, we proposed deep evolving denoising autoencoder (DEVDAN). The main feature of DEVDAN lies in the coupled-generative-discriminative-learning phases which enable DEVDAN to exploit both labeled and unlabeled samples. The evolving trait of DEVDAN is carried out in both phases attempting to handle concept changes with or without label. We put forward DAE to handle newly incoming data in an unsupervised manner. In this phase, the evolving mechanism is controlled by the NS formula. Unlike ADL, the NS formula in the generative phase is derived from the squared reconstruction error. After the labeling process is finished, the discriminative phase is executed to improve the generalization power with labeled samples. The hidden nodes growing and pruning mechanism is governed by the same NS formula as for ADL. The two training phases are executed alternately whenever a data batch comes creating a continual learning cycle. The learning policy of DEVDAN can be observed in Fig. 3. DEVDAN offers improvement over ADL in some cases, especially in a situation where the number of labeled data is less than the number of unlabeled data. Nevertheless, DEVDAN does not involve any learning mechanism which specifically addresses the lack of labeled data.
 

Figure 3:The learning policy of DEVDAN

Ashfahani, Andri, Mahardhika Pratama, Edwin Lughofer, and Yew-Soon Ong. "DEVDAN: Deep evolving denoising autoencoder." Neurocomputing 390 (2020): 297-314.

1.1.4 Weakly Supervised Deep Learning Approach in Streaming Environments 
The general trend of deep learning research changed dramatically during the midst of the work on this thesis with the presentation from Yann LeCun in which he stated that unsupervised, semi-supervised and self-supervised learning problems are the major challenges of AI for the next decade. Semi-supervised and self-supervised learning behaves similarly to supervised learning in which it learns a function from input-output pairs of data. However, they have additional features to address the lack of labeled samples. That is, they can automatically generate labels from the input data. In the viewpoint of evolving data streams, this can be adopted to circumvent one of major limitations in data streams. That is, all true class labels are not immediately available after receiving the data. The third paper in this thesis presents a self-evolving deep neural network, namely Parsimonious Network (ParsNet), as a solution of weakly-supervised data stream problem. A self-labeling strategy with hedge (SLASH) is proposed in which its auto-correction mechanism copes with \textit{the accumulation of mistakes} significantly affecting the model's generalization. ParsNet is developed from a closed-loop configuration of the self-evolving generative and discriminative training processes similar to DEVDAN. The learning policy is illustrated in Fig. 4. When tested on benchmark datasets, ParsNet outperforms prominent algorithms with substantial margin in the high-dimensional data streams and infinite delay simulation protocol.
 

Figure 4:The learning policy of ParsNet

Pratama, Mahardhika, Ashfahani, Andri, and Abdul Hady. "Weakly supervised deep learning approach in streaming environments." In 2019 IEEE International Conference on Big Data (Big Data), pp. 1195-1202. IEEE, 2019.

Conclusions and Future Works.
Finally, we draw conclusions from several works that have been done. In future work, we are interested in investigating the fully unsupervised for continual learning in data stream environments. The ideas from state-of-the-arts unsupervised learning literature will be incorporated to find the effective algorithm for this scenario. Separately, we are also interested in developing methodologies to incrementally construct convolutional neural networks (CNNs) from scratch. It has a lot of components and hyper-parameters, i.e, convolutional layer, fully connected layer, number of layers, number of filters, filter size etc, making it difficult to construct a CNN for a particular problem. Most methodologies to find the optimal CNN architecture are based on meta-learning and reinforcement learning which require resources. We will try to develop the continual evaluation methods to assess the CNN performance which are then used to control the automatic construction of CNN. It is expected that the result possesses less computational complexity as it is purely built upon a data driven approach which can be executed in a single-pass learning fashion.


1.2 Computer Vision (CV)

1.2.1 Autonomous Convolutional Neural Networks (AutoCNN) 

1.2.2 Computer Vision (CV) for Construction

1.2.3 Physical rule-based reflection removal with camera calibration

Researcher: Jinnan Chen


Separating transmission image from a single reflection-contaminated image is an ill-posed computer vision problem which has been studied for a long time in computer vision community. In order to make this problem more trackable, we aim to jointly remove the reflection part and calibrate the orientation of glass and the field of view (FoV) of the camera by using a reflection amplitude coefficient map as a calibration cue. We synthesize the paired training data in a physical rule-based way and thus encode these geometric constraints into the learnable parameters of our image separation network. For camera calibration, different from existing methods, our proposed solution is agnostic to image contents so it is more robust for different real-world scenarios. We proposed a learning-based method that fully exploits all entries of the reflection amplitude coefficient map to estimate the glass plane orientation and FoV of the camera. Besides, we also collect a dataset containing 320 samples as well as their camera parameters for evaluation. The experiments demonstrate that our method not only facilitates the performance of single image reflection removal but also contributes to solve single image camera calibration in such cases. What’s more, we demonstrate our by-product output helps alleviate another ill-posed problem of estimating the panorama from a single image.
 
1.3 ?

Researcher: A



1.4 Adversarial Machine Learning

Researcher: Bai Tao


1.4.1 AI-GAN: Attack-Inspired Generation of Adversarial Examples

In this paper, we propose Attack-Inspired GAN (AI-GAN) with a different training strategy to solve this problem. AI-GAN is a two-stage method, in which we use projected gradient descent (PGD) attack to inspire the training of GAN in the first stage and apply standard training of GAN in the second stage. Once trained, the Generator can approximate the conditional distribution of adversarial instances and generate imperceptible adversarial perturbations given different target classes. We conduct experiments and evaluate the performance of AI-GAN on MNIST and CIFAR-10. Compared with AdvGAN, AI-GAN achieves higher attack success rates with similar perturbation magnitudes.



Bai Tao, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, and Bo Li. "AI-GAN: Attack-Inspired Generation of Adversarial Examples." arXiv preprint arXiv:2002.02196 (2020).
 
1.4.2 Generating Adversarial yet Inconspicuous Patches with a Single Image
Deep neural networks have been shown vulnerable to adversarial patches, where exotic patterns can result in models wrong prediction. Nevertheless, existing approaches to adversarial patch generation hardly con-sider the contextual consistency between patches and the image background, causing such patches to be easily detected and adversarial attacks to fail. On the other hand, these methods require a large amount of data for training, which is computationally expensive. To overcome these challenges, we propose an approach to generate adversarial yet inconspicuous patches with one single image. In our approach, adversarial patches are produced in a coarse-to-fine way with multiple scales of generators and discriminators. Contextual information is encoded during the Min-Max training to make patches consistent with surroundings. The selection of patch location is based on the perceptual sensitivity of victim models. Through extensive experiments, our approach shows strong attacking ability in both the white-box and black-box setting. Experiments on saliency detection and user evaluation indicate that our adversarial patches can evade human observations, demonstrating the inconspicuousness of our approach. Lastly, we show that our approach preserves the attack ability in the physical world.



Luo, Jinqi, Tao Bai, Jun Zhao, and Bo Li. "Generating Adversarial yet Inconspicuous Patches with a Single Image." arXiv preprint arXiv:2009.09774 (2020).
 
1.4.3 Feature Distillation With Guided Adversarial Contrastive Learning
Deep learning models are shown to be vulnerable to adversarial examples. Though adversarial training can enhance model robustness, typical approaches are computationally expensive. Recent works proposed to transfer the robustness to adversarial attacks across different tasks or models with soft labels. Compared to soft labels, the feature contains rich semantic information and holds the potential to be applied to different downstream tasks. In this paper, we propose a novel approach called Guided Adversarial Contrastive Distillation (GACD), to effectively transfer adversarial robustness from teacher to student with features. We first formulate this objective as contrastive learning and connect it with mutual information. With a well-trained teacher model as an anchor, students are expected to extract features similar to the teacher. Then considering the potential errors made by teachers, we propose sample reweighted estimation to eliminate the negative effects from teachers. With GACD, the student not only learns to extract robust features, but also captures structural knowledge from the teacher. By extensive experiments evaluating over popular datasets such as CIFAR-10, CIFAR-100 and STL-10, we demonstrate that our approach can effectively transfer robustness across different models and even different tasks, and achieve comparable or better results than existing methods. Besides, we provide a detailed analysis of various methods, showing that students produced by our approach capture more structural knowledge from teachers and learn more robust features under adversarial attacks.
 
Bai, Tao, Jinnan Chen, Jun Zhao, Bihan Wen, Xudong Jiang, and Alex Kot. "Feature Distillation With Guided Adversarial Contrastive Learning." arXiv preprint arXiv:2009.09922 (2020).

1.5 Reinforcement Learning
See 
4.1.1 Deep reinforcement learning based intelligent reflecting surface for secure wireless communications
4.1.2 Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach

1.6 Federated Learning
1.6.1 Why federated learning is right for you
Federated learning is a booming field, both in academia and in industry!
Federated learning was invented by Google in 2017. Federated learning will have impacts similar to those of other Google inventions: TensorFlow, MapReduce, etc.
Many high-tech companies are following Google to do federated learning. These companies include Apple, Amazon, Facebook, Microsoft, Alibaba, Tencent, WeBank, ByteDance, SenseTime …
The first academic paper on federated learning, published by Google in 2017, received over 1000 citations in July 2020:
http://proceedings.mlr.press/v54/mcmahan17a.html  
58 big names in academia (MIT, Stanford, CMU, Berkeley, Princeton, Cornell, NTU, UIUC, EPFL) and industry (Google, WeBank) together uploaded a 100-page paper to arXiv in December 2019: https://arxiv.org/abs/1912.04977
You know federated learning is hot when you see this. Nothing like this happened for other topics before. This paper has been cited for over 100 times in less than 6 months.
NTU is a hotbed for federated learning research. 
Turing Award Winners and Academicians from National Academy of Science/Engineering are working on federated learning. 
Papers on federated learning have won numerous best paper awards in academic conferences and journals. 


1.6.2 Privacy-Preserving Federated learning-based UAV-enabled wireless networks
Deploying UAVs as flight BSs is able to flexibly collect data and implement AI model training for ground devices, but it is impractical for a large number of devices to transmit their  raw data to UAV servers due to the privacy concern and limited communication resources for data transmission. Moreover, as the energy capacity, storage, and computational ability of UAVs are limited, it is still challenging for UAVs to process/train a large amount of raw data. In face of the challenges, federated learning (FL) emerges as a promising paradigm aiming to protect device privacy by enabling devices to train AI models locally without sending their raw data to a server. Instead of training AI models at the data server, FL enables devices to execute local training on their own data, which generally uses the gradient descent optimization method.

Fig. 11. Federated learning-based UAV-enabled wireless networks.
 
In the FL instance, as illustrated in Fig. 11, each device has its own personal dataset and it is willing to upload a part of inflammation (i.e., AI model parameters) to its associated UAV server in a privacy-preserving manner. In addition, devices involved in a common computing task (e.g., training a classification model) are more likely to work with others together to finish the task collaboratively, by adopting AI techniques. These devices will update their own local AI model parameters to associated UAV servers for global model aggregation. Each device processes the local model training based on its local raw dataset without sharing the raw data with other devices, to protect the privacy of data providers. After completing local model training, each device will send its local model parameters to its associated UAV server by the uplink communication channel, and the corresponding UAV server aggregates the local parameters from the selected devices before broadcasting the aggregated global parameters to the devices by the downlink communication channel.
In Fig. 12, we compare the accuracy performance versus the number of global rounds and wall-clock time for different FL approaches, where several devices are set as low-quality participants. The low-quality participants are with low communication and computation capabilities, and even have low-quality training parameters. From Fig. 12(a), we can observe that both the AFL and SFL approaches with device selection require about 25 global rounds to achieve an accuracy of 90.0%, and both of them have similar convergence speed and accuracy performance. However, at each global round, SFL has to wait until all the selected devices respond, while AFL only needs a number of selected devices' response to move on to the next round which decreases the aggregation completion time during the learning process as shown in Fig. 12(b). In addition, both the AFL and SFL approaches with device selection achieve higher accuracy and convergence speed than those of the AFL approach without device selection. The results illustrate that the proposed device selection scheme can prevent low-quality devices from affecting the learning accuracy, and enhances the system performance significantly. 
 
  
Fig. 12. Accuracy comparison versus (a) number of global communication rounds and (b) wall-clock time.
From Fig. 12(b), we can see that the accuracy of all approaches improves with the increase of the wall-clock time. However, by comparing different approaches, the proposed AFL approach with device selection outperforms the other two approaches in terms of both the convergence speed and accuracy. The reason lies in the fact that the AFL approach without device selection may enable the low-quality devices to participate in the FL model aggregation, where the low-quality model parameters decrease the overall accuracy, as well as devices with low communication and computation capacities need more time to complete the model aggregation. In addition, the SFL approach with device selection has to wait for all selected devices to complete their local model parameters update, among which there may require long computation time due to low computation capability. Consequently, each global communication round of the SFL approach with device selection requires more time to finish model aggregation, and hence its accuracy performance slowly improves with the increase of wall-clock time. The results from Fig. 12 demonstrate that the proposed AFL approach with device selection is capable of improving both the convergence speed and aggregation accuracy performance.  
[7] Helin Yang, Zehui Xiong, Jun Zhao, Kwo Yan Lam, Sumei Sun, and Liang Xiao, “Privacy-Preserving Federated Learning for UAV-Enabled Networks: Learning-Based Joint Scheduling and Resource Management,” submitted to IEEE Journal on Selected Areas in Communications by Oct. 2020.  
2. City Brain / Smart Nation: Internet of Things (IoT), Cloud/Edge/Fog Computing
Artificial Intelligence of Things (AIoT) with federated learning, deep learning, reinforcement learning, adversarial machine learning, etc.
Internet of Things (IoT)
Cloud/Edge/Fog Computing
Blockchain 
Security and Privacy
     Figure 1. A Hierarchical View of City Brain / Smart Nation.
     Figure 2. A View of City Brain / Smart Nation Highlighting Industrial Applications.
     Figure 3. Industrial Applications of City Brain / Smart Nation.


3. Security / Privacy
3.1 Adversarial Machine Learning
See 1.4 Adversarial Machine Learning
3.2 Secure Communications
See 
4.1.1 Deep reinforcement learning based intelligent reflecting surface for secure wireless communications
4.1.2 Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach

3.3 Privacy-Preserving Federated Learning
See 1.6.2 Federated learning-based UAV-enabled wireless networks

3.4 Differential Privacy for Fog Computing
Researcher: Mengmeng Yang 
 
Secure Hot Path Crowdsourcing with Local Differential Privacy under Fog Computing Architecture
For a traditional crowdsourcing system, the server interacts with the participants directly after receiving the tasks from the requester. However, offloading the data to the cloud introduces unforeseeable delay and heavy communication burden, especially when multiple interactions are needed. A better alternative solution is to take advantage of the nearby infrastructures or devices to process the data and send the processed data back to the cloud. This process is called edge computing, also known as fog computing. Though edge computing enhances crowdsourcing, the collected data can also be used by the adversary to make sensitive inferences. The traditional solutions rely on the premise that the fog node is trusted and a series of privacy strategies are performed by the fog node on top of the user’s real data. However, the fog node may not be trusted either. Therefore, the information needs to be protected locally by perturbing it before it leaves the user’s devices. In this paper, we consider the location privacy problem for hot path statistics in the crowdsourcing system under fog computing architecture. To provide a much more accurate statistic while preserving the user’s location information locally, we proposed a novel solution that combines both local differential privacy technology and secret sharing technology.


Framework 
(1)The proposed method can achieve a much higher accuracy even if the privacy budget is quite small. The error of the proposed method only comes from the sampling processes (e.g. worker selection and node selection), which are controlled by privacy budget and sample rate respectively. Even when the privacy budget is very small, we can still expect to have around half of the participating workers to contribute to the statistical count by adjusting the parameter. (2)The proposed method can achieve a good performance even when a limited number of workers participate. This is because all the selected workers report the true value through secret sharing instead of a perturbed value to the fog node. As we mentioned, the error only comes from the sampling processes, which are independent of the data dimension and have a much smaller statistical variance.





4. 6G Wireless Networks (including AI and Intelligent Reflecting Surfaces)

Researcher: Yang Helin  

4.1 Intelligent Reflecting Surfaces (IRS) for 6G Wireless Networks
A new paradigm, called intelligent reflecting surface (IRS), has been proposed as a promising technique to achieve high spectrum efficiency and energy efficiency, and enhance secrecy rate in the fifth generation (5G) and beyond wireless communication systems. In particular, IRS is a uniform planar array which is comprised of a number of low-cost passive reflecting elements, where each of elements adaptively adjusts its reflection amplitude and/or phase to control the strength and direction of the electromagnetic wave, hence IRS is capable of enhancing and/or weakening the reflected signals at different users.  As a result, the reflected signal by the IRS can increase the received signal at legitimate users while suppressing the signal at the eavesdroppers. Hence, from the PLS perspective, some innovative studies have been recently devoted to performance optimization for IRS-aided secure communications.
4.1.1 Deep reinforcement learning based intelligent reflecting surface for secure wireless communications
We consider an IRS-aided secure communication system, as shown in Fig. 1, where the BS is equipped with N antennas to serve K single-antenna legitimate mobile users (MUs) in the presence of M single-antenna eavesdroppers. An IRS with L reflecting elements is deployed in the system to assist secure wireless communications from the BS to the MUs. The IRS is equipped with a controller to coordinate with the BS. For the ease of practical implementation, the maximal reflection without power loss at the IRS is considered since the reflecting elements are designed to maximize the reflected desired signal power to the MUs. In addition, unauthorized eavesdroppers aim to eavesdrop any of the data streams of the MUs.  Hence, the use of reflecting beamforming at IRS is also investigated to improve the achievable secrecy rate at the MUs while suppressing the wiretapped data rate at the eavesdroppers. In addition, we explicitly state that the eavesdroppers cannot collide.  
 
Fig. 1. IRS-aided secure communication under multiple eavesdroppers. 

Considering the fact that the IRS-aided secure communication system has high-dimensional and high-dynamical characteristics according to the system state that is defined in and uncertain CSI, we propose a deep PDS-PER learning based secure beamforming approach, as shown in Fig. 2, where PDS-learning and PER mechanisms are utilized to enable the learning agent to learn and adapt faster in dynamic environments. In detail, the agent utilizes the observed state (i.e, CSI, previous secrecy rate, QoS satisfaction level), the feedback reward from the environment as well as the historical experience from the replay buffer to train its learning model. After that, the agent employs the trained model to make decision beamforming matrices based on its learned policy. The procedures of the proposed learning based secure beamforming are provided in the following subsections.  
 
Fig. 2. Deep PDS-PER learning based beamforming for IRS-aided secure communications.
 
In Fig. 3, the achievable secrecy rate and QoS satisfaction level performance of all approaches are evaluated through changing the IRS elements. For the secure beamforming approaches assisted by the IRS, their achievable secrecy rates and QoS satisfaction levels significantly increase with the number of the IRS elements. The improvement results from the fact that more IRS elements, more signal paths and signal power can be reflected by the IRS to improve the received SINR at the MUs but to decrease the received SINR at the eavesdroppers. In addition, the performance of the approach without the IRS remains constant under the different numbers of the IRS elements. From Fig. 3(a), it is found that the secrecy rate of the proposed learning approach is higher than those of the Baseline 1 and DQN approaches, especially, their performance gap also obviously increases with $L$, this is because that with more reflecting elements at the IRS, the proposed deep PDS-PER learning based secure communication approach becomes more flexible for optimal phase shift (reflecting beamforming) design and hence achieves higher gains. In addition, from Fig. 3(b) compared with the Baseline 1 and DQN approaches, as the reflecting elements at the IRS increases, we observe that the proposed learning approach is the first one who attains 100% QoS satisfaction level. These superior achievements are based on the particular design of the QoS-aware reward function for secure communication.
 

Fig. 3. Performance comparisons versus the number of IRS elements.
 
4.1.2 Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach
	As shown in Fig. 4, this paper considers an IRS-assisted communication system, which consists of one BS with N antennas and K single-antenna legitimate user equipments (UEs) located at the cell-edge. The IRS composed of M reflecting elements is deployed to provide additional communication links so as to improve the performance for the UEs over a given frequency band. The direct communication links of cell-edge UEs may suffer high signal attenuation and these links are severely blocked by obstacles when these UEs are located in dead zones. In addition, as illustrated in Fig. 4, a malicious (or unfriendly) multi-antenna jammer is located near the  UEs who attempt to interfere with the  transmissions by sending faked or replayed jamming signal for the UEs via  antennas, in order to degrade the  communication performance. In this case, deploying the IRS can effectively enhance the desired signal power and mitigate the jamming interference generated from the jammer by designing the reflecting beamforming at the IRS.  

Fig. 4. Illustration of an IRS-assisted communication system against a multi-antenna jammer.
  	In order to obtain the optimal anti-jamming policy against smart jamming, we propose a fast fuzzy WoLF-PHC-based joint power allocation and reflecting beamforming for IRS-assisted communication systems, as shown in Fig. 5, where WoLF-PHC is utilized to enable the learning agent to learn and adapt faster in dynamic uncertain environments, and FSA is used to enable Q-Learning to represent the system states with a fixed number of aggregate states and represent continuous state spaces as discrete. In the IRS-assisted system, the learning agent observes a system state and receives an instantaneous reward by interacting with the environment. Then, such information is leveraged to train the learning model to choose the anti-jamming policy with the maximum Q-function value. After that, according to the selected policy, the action is chosen to make decisions in terms of power allocation and reflecting beamforming. The procedures of the proposed learning based decision making approach are provided in the following analysis.  

Fig. 5. Fuzzy WoLF-PHC-based anti-jamming policy for IRS-assisted systems.
 
	Fig. 6 compares the performance of the four approaches for different reflecting elements number. It can be seen that, except the optimal PA approach without IRS, the performance of all IRS-based approaches increases with $M$, and greatly outperforms the optimal PA approach without IRS. The reason is that the IRS has the ability to support higher degrees of freedom for performance optimization, resulting in the great performance gains obtained by employing the IRS against smart jamming over the traditional system without IRS. Specifically, when  M = 20, the system achievable rate gain of the proposed learning approach over the optimal PA approach without IRS is only about 2.36 bits/s/Hz, while this value is improved to 12.21 bits/s/Hz when  M = 100. In addition, by deploying the IRS, the SINR protection level is significantly improved compared with the optimal PA approach without IRS assistance. Such performance improvement results from the fact that higher power can be achieved at the IRS by increasing M, and a higher reflecting beamforming gain is achieved to design the IRS phase shifts to improve the received desired signal as well as mitigate the jamming interference from the smart jammer by increasing M. 	
 
Fig. 6 Performance comparisons versus the number of IRS elements.
 	In addition, from Fig. 6(a), we can also observe that the achievable rate of the proposed learning approach outperforms both the fast Q-Learning and Baseline 1 approaches, and especially, the performance gap significantly increases with M. At the same time, Fig. 6(b) shows that, as the reflecting elements increases, the proposed learning approach is the first one can achieve 100% SINR protection level compared with other approaches. This is because deploying more reflecting elements, the proposed fuzzy WoLF-PHC-learning based joint power allocation and reflecting beamforming approach becomes more flexible for optimal phase shift (reflecting beamforming) design and hence achieves the higher performance gain. These results also show that employing IRS into wireless communications improves the anti-jamming communication performance against smart jamming.
 
[1] Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, and Liang Xiao, “Deep reinforcement learning based intelligent reflecting surface for secure wireless communications,” IEEE Transactions on Wireless Communications. (Accepted) DOI: 10.1109/TWC.2020.3024860.
[2]   Helin Yang, Yang Zhao, Zehui Xiong, Jun Zhao, Dusit Niyato, Kwok-Yan Lam, and Qingqing Wu, “Deep reinforcement learning based intelligent reflecting surface for secure wireless communications” IEEE Global Communications Conference (GLOBECOM), 2020, Taipei, Taiwan, Dec. 2020. (Accepted).
[3]   Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, Massimo Tornatore, and Stefano Secci, “Intelligent reflecting surface assisted anti-jamming communications based on reinforcement learning” IEEE Global Communications Conference (GLOBECOM), Taipei, Taiwan, Dec. 2020. (Accepted).
[4] Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, and H. Vincent Poor, “Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach,” IEEE Transactions on Wireless Communications. (Major revision) https://arxiv.org/abs/2004.12539.
 
4.2 Artificial Intelligence-Enabled Intelligent 6G Networks 
 	In order to support near-instant and seamless super-connectivity, an integrated space–air–ground–underwater network (ISAGUN) will be the core potential architecture of 6G networks, as shown in Fig. 7, where ISAGUN mainly consists of the following four tiers:
·    Space-network tier deploys low Earth orbit, medium Earth orbit, and geostationary Earth orbit satellites to provide orbit or space services for unserved areas which are not covered by ground networks.
·    Air-network tier employs various aerial platforms including unmanned aerial vehicles (UAVs), airships, and balloons associated with flying base stations (BSs) to support flexible and reliable wireless connectivity for remote areas or urgent events.
·    Ground-network tier is the main solution for supporting diverse services for a massive number of devices. In order to satisfy various services, this layer mainly exploits low-frequency, microwave, mmWave, visible light and Terahertz (THz) bands for 6G networks.
·    Underwater-network tier aims to provide underwater communication connectivity, observation and monitoring services for broad-sea and deep-sea activities.
 
Fig.7. The typical architecture of 6G network (ISAGUN). V2X: vehicle to everything; VLC: visible light communication; RAN: radio access networks; SDN: software-defined networking; NFV: network function virtualization; PHY: physical layer; MAC: medium access control.
 
The development of 6G networks will be large-scale, multi-layered, high complex, dynamic, and heterogeneous. In addition, 6G networks need to support seamless connectivity and guarantee diverse QoS requirements of the huge number of devices, as well as process large amounts of data generated from physical environments. AI techniques with powerful analysis ability, learning ability, optimizing ability and intelligent recognition ability, which can be employed into 6G networks to intelligently carry out performance optimization, knowledge discovery, sophisticated learning, structure organization and complicated decision making. With the help of AI, we present an AI-enabled intelligent architecture for 6G networks which is mainly divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer, as shown in Fig. 8. This four-layer bottom-up architecture can clearly serve as a transparent bridge between the physical world (with general physical/virtual things, objects, resources, etc.) and social world (with human demand, social behavior, etc.).

Fig. 8. The architecture of AI-enabled intelligent 6G networks.
 
   In 5G and B5G networks shown in Fig. 9, massive communication links aim to access the limited radio spectrum, which can be modelled as a multi-agent RL problem, where each communication link is regarded as a learning agent to interact with network environment to learn its experience, and the learned experience is then utilized to optimize its own spectrum access strategy. Massive agents explore the outside network environment and search spectrum access and power control strategies according to the observations of the network state. 

Fig. 9. DQN training based intelligent subchannel assignment and power control for massive access.
 
    Fig. 10 depicts the EE performance and the transmission success probability with varying number of devices when the packet arrival rate is 0.03 packets/slot/per communication link, the reliability and latency thresholds are 99.999% and 5ms, respectively. Note: Transmission success probability is the sum probability of the satisfied URLLC probability and the satisfied minimum data rate probability. From Fig. 10, we can observe that the performance of the four approaches decreases as the increased number of devices increases. As more devices lead to more communication links, all links attempt to access the limited spectrum radio which increases co-channel interference, and more devices consume the more energy, hence the EE performance decreases in this case as shown in Fig. 10 (a). At the same time, from Fig. 10 (b), we find that the transmission success probability can be maintained at a good level when the number of devices is moderate (less than 1800), but it declines significantly once the number of devices increases beyond an acceptable margin. Such the phenomenon has the following reasons: the serious co-channel interference decreases the channel quality; the massive number of communication links require to be served and various QoS requirements need to be satisfied, all approaches cannot complete all the massive number of services under the limited spectrum resource, thereby leading to the decease of the probability of the transmission success links.  
 
Fig. 10. Performance comparisons with different total numbers of devices.
 
 
 
[5] Helin Yang, Arokiaswami Alphones, Zehui Xiong, Dusit Niyato, and Jun Zhao, “Artificial intelligence-enabled intelligent 6G networks”, IEEE Network. (Accepted) DOI:  10.1109/MNET.011.2000195.
[6] Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Chau Yuen, and Ruilong Deng, “Deep reinforcement learning based massive access management for ultra-reliable low-latency communications,” IEEE Transactions on Wireless Communications. (Major revision). https://arxiv.org/abs/ 2002.08743.

4.3 Privacy-Preserving Federated Learning for Wireless Networks
See 1.6.2 Privacy-Preserving Federated Learning for Wireless Networks

  
 
			
            
            <br>
            <br>
            <br>
			
		  


            </div>
            <!-- .container -->
          
          </div><!-- InstanceEndEditable -->
        </div><!-- .container -->
      </div>
      </div>
            <!-- .container -->
    </div>
    <!-- .fullwidth-block -->
    </main>
    </div>
    <footer>
        <div class="site-footer" data-bg-image="images/page-head-1.jpg"
            style="background-image: url(&quot;images/page-head-1.jpg&quot;);">
            <div class="container">
                Email: junzhao@ntu.edu.sg
                <br>
                <br>
                <img src="images/NTULogo.jpg">
                <br>
                <br>
                <h3>School of Computer Science and Engineering (SCSE)</h3>
                Nanyang Technological University, 50 Nanyang Avenue, Singapore 639798, Singapore
                <br>
                <br>
            </div>
        </div>
    </footer>
    <script src="js/jquery-1.11.1.min.js"></script>
    <script src="js/plugins.js"></script>
    <script src="js/app.js"></script>
    <script src="js/google-track.js"></script>
    <script src="js/slideshow.min.js"></script>
    <!-- InstanceBeginEditable name="script" -->
    <!-- InstanceEndEditable -->
</body>
<!-- InstanceEnd -->

</html>
