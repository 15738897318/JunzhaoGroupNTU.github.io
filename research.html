<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_hc6gm3lqhsbr-3>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-3}ol.lst-kix_hc6gm3lqhsbr-6.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-6 0}.lst-kix_sxdva6gs1m3z-6>li:before{content:"\0025cf  "}.lst-kix_sxdva6gs1m3z-7>li:before{content:"\0025cb  "}ol.lst-kix_hc6gm3lqhsbr-3.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-3 0}.lst-kix_sxdva6gs1m3z-8>li:before{content:"\0025a0  "}ul.lst-kix_sxdva6gs1m3z-1{list-style-type:none}ul.lst-kix_sxdva6gs1m3z-0{list-style-type:none}.lst-kix_hc6gm3lqhsbr-0>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-0,decimal) ". "}.lst-kix_hc6gm3lqhsbr-2>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-2,lower-roman) ". "}ul.lst-kix_sxdva6gs1m3z-5{list-style-type:none}ul.lst-kix_sxdva6gs1m3z-4{list-style-type:none}ul.lst-kix_sxdva6gs1m3z-3{list-style-type:none}.lst-kix_hc6gm3lqhsbr-1>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-1,lower-latin) ". "}ul.lst-kix_sxdva6gs1m3z-2{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-0{list-style-type:none}.lst-kix_hc6gm3lqhsbr-2>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-2}.lst-kix_hc6gm3lqhsbr-4>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-4,lower-latin) ". "}ol.lst-kix_hc6gm3lqhsbr-2{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-1{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-4{list-style-type:none}.lst-kix_hc6gm3lqhsbr-3>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-3,decimal) ". "}ol.lst-kix_hc6gm3lqhsbr-3{list-style-type:none}.lst-kix_hc6gm3lqhsbr-5>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-5}ol.lst-kix_hc6gm3lqhsbr-6{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-5{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-8{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-7{list-style-type:none}.lst-kix_hc6gm3lqhsbr-8>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-8,lower-roman) ". "}.lst-kix_hc6gm3lqhsbr-8>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-8}.lst-kix_t2no3e9jpit1-0>li:before{content:"\0025a0  "}.lst-kix_t2no3e9jpit1-1>li:before{content:"\0025cb  "}.lst-kix_hc6gm3lqhsbr-5>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-5,lower-roman) ". "}ol.lst-kix_hc6gm3lqhsbr-7.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-7 0}.lst-kix_hc6gm3lqhsbr-6>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-6,decimal) ". "}ol.lst-kix_hc6gm3lqhsbr-4.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-4 0}.lst-kix_hc6gm3lqhsbr-7>li:before{content:"" counter(lst-ctn-kix_hc6gm3lqhsbr-7,lower-latin) ". "}.lst-kix_t2no3e9jpit1-6>li:before{content:"\0025cf  "}ul.lst-kix_1r9d50j0cire-7{list-style-type:none}.lst-kix_hc6gm3lqhsbr-0>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-0}.lst-kix_hc6gm3lqhsbr-6>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-6}ul.lst-kix_1r9d50j0cire-8{list-style-type:none}ul.lst-kix_1r9d50j0cire-5{list-style-type:none}.lst-kix_t2no3e9jpit1-4>li:before{content:"\0025cb  "}.lst-kix_t2no3e9jpit1-8>li:before{content:"\0025a0  "}ul.lst-kix_1r9d50j0cire-6{list-style-type:none}ul.lst-kix_1r9d50j0cire-3{list-style-type:none}.lst-kix_1r9d50j0cire-8>li:before{content:"\0025a0  "}.lst-kix_t2no3e9jpit1-5>li:before{content:"\0025a0  "}ul.lst-kix_1r9d50j0cire-4{list-style-type:none}ul.lst-kix_1r9d50j0cire-1{list-style-type:none}.lst-kix_1r9d50j0cire-7>li:before{content:"\0025cb  "}.lst-kix_t2no3e9jpit1-2>li:before{content:"\0025a0  "}ul.lst-kix_1r9d50j0cire-2{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-1.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-1 0}ul.lst-kix_1r9d50j0cire-0{list-style-type:none}.lst-kix_1r9d50j0cire-6>li:before{content:"\0025cf  "}.lst-kix_t2no3e9jpit1-3>li:before{content:"\0025cf  "}ol.lst-kix_hc6gm3lqhsbr-8.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-8 0}.lst-kix_1r9d50j0cire-3>li:before{content:"\0025cf  "}.lst-kix_1r9d50j0cire-1>li:before{content:"\0025cb  "}.lst-kix_1r9d50j0cire-5>li:before{content:"\0025a0  "}.lst-kix_1r9d50j0cire-0>li:before{content:"\0025a0  "}.lst-kix_1r9d50j0cire-4>li:before{content:"\0025cb  "}ul.lst-kix_sxdva6gs1m3z-8{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-0.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-0 0}ul.lst-kix_sxdva6gs1m3z-7{list-style-type:none}ul.lst-kix_sxdva6gs1m3z-6{list-style-type:none}.lst-kix_1r9d50j0cire-2>li:before{content:"\0025a0  "}.lst-kix_t2no3e9jpit1-7>li:before{content:"\0025cb  "}ol.lst-kix_hc6gm3lqhsbr-5.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-5 0}.lst-kix_sxdva6gs1m3z-5>li:before{content:"\0025a0  "}ul.lst-kix_t2no3e9jpit1-3{list-style-type:none}ul.lst-kix_t2no3e9jpit1-4{list-style-type:none}ul.lst-kix_t2no3e9jpit1-1{list-style-type:none}ol.lst-kix_hc6gm3lqhsbr-2.start{counter-reset:lst-ctn-kix_hc6gm3lqhsbr-2 0}.lst-kix_sxdva6gs1m3z-4>li:before{content:"\0025cb  "}ul.lst-kix_t2no3e9jpit1-2{list-style-type:none}ul.lst-kix_t2no3e9jpit1-7{list-style-type:none}ul.lst-kix_t2no3e9jpit1-8{list-style-type:none}.lst-kix_hc6gm3lqhsbr-7>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-7}ul.lst-kix_t2no3e9jpit1-5{list-style-type:none}.lst-kix_sxdva6gs1m3z-3>li:before{content:"\0025cf  "}ul.lst-kix_t2no3e9jpit1-6{list-style-type:none}.lst-kix_hc6gm3lqhsbr-4>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-4}.lst-kix_sxdva6gs1m3z-0>li:before{content:"\0025a0  "}.lst-kix_sxdva6gs1m3z-2>li:before{content:"\0025a0  "}ul.lst-kix_t2no3e9jpit1-0{list-style-type:none}.lst-kix_hc6gm3lqhsbr-1>li{counter-increment:lst-ctn-kix_hc6gm3lqhsbr-1}.lst-kix_sxdva6gs1m3z-1>li:before{content:"\0025cb  "}ol{margin:0;padding:0}table td,table th{padding:0}.c8{-webkit-text-decoration-skip:none;color:#1155cc;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-family:"Arial";font-style:normal}.c22{background-color:#ffffff;color:#2e414f;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c56{margin-left:37pt;padding-top:0pt;text-indent:-10pt;padding-bottom:0pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c48{color:#222222;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c7{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c4{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c14{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Verdana";font-style:normal}.c30{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10.5pt;font-family:"Arial";font-style:normal}.c64{margin-left:-11pt;padding-top:0pt;padding-bottom:5pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c23{color:#ff0000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c40{margin-left:36pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c16{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c21{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c28{margin-left:18pt;padding-top:3pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c49{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:8pt;font-family:"Arial";font-style:normal}.c34{padding-top:20pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c51{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c44{padding-top:12pt;padding-bottom:5pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c15{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c58{font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c39{padding-top:18pt;padding-bottom:6pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c53{padding-top:16pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c31{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c27{padding-top:12pt;padding-bottom:12pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:center}.c11{padding-top:12pt;padding-bottom:0pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c43{padding-top:16pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c47{padding-top:10pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c50{padding-top:12pt;padding-bottom:6pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c65{padding-top:4pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c35{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c52{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c20{padding-top:0pt;padding-bottom:5pt;line-height:1.15;orphans:2;widows:2;text-align:justify}.c63{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c6{padding-top:12pt;padding-bottom:12pt;line-height:1.1500000000000001;orphans:2;widows:2;text-align:justify}.c17{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c25{background-color:#ffffff;margin-left:36pt;padding-left:0pt}.c29{background-color:#ffffff;font-size:10pt;color:#222222}.c12{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c42{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;text-decoration:underline}.c26{font-size:10pt;font-family:"Verdana";font-weight:400}.c18{color:inherit;text-decoration:inherit}.c13{padding:0;margin:0}.c55{text-indent:11pt}.c19{height:11pt}.c10{font-size:16pt}.c36{font-size:7pt}.c33{page-break-after:avoid}.c61{font-size:11pt}.c45{height:14pt}.c62{text-indent:9pt}.c57{font-weight:700}.c46{font-size:10pt}.c24{color:#434343}.c38{font-size:9pt}.c59{margin-left:13pt}.c32{color:#835ea5}.c54{font-style:italic}.c37{background-color:#e4e8ee}.c41{background-color:#ffffff}.c60{color:#ff0000}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c12"><p class="c7"><span class="c2"></span></p><p class="c65"><span class="c8"><a class="c18" href="#h.ckz6p59xskk8">1. Artificial Intelligence (AI)</a></span></p><p class="c28"><span class="c8"><a class="c18" href="#h.1lajoyme23kw">1.1 Autonomous Deep Learning </a></span><span class="c17">ZZ</span></p><p class="c28"><span class="c8"><a class="c18" href="#h.ucnzv4to5n0x">1.2 Computer Vision (CV)</a></span></p><p class="c28"><span class="c8"><a class="c18" href="#h.ondb4qvbq0bk">1.3 ?</a></span></p><p class="c28"><span class="c8"><a class="c18" href="#h.8h7r4ihhfag2">1.4 Adversarial Machine Learning</a></span></p><p class="c28"><span class="c8"><a class="c18" href="#h.wn19rhcbp828">1.5 Reinforcement Learning</a></span></p><p class="c28"><span class="c8"><a class="c18" href="#h.j3j7w5zedugr">1.6 Federated Learning</a></span></p><p class="c47"><span class="c8"><a class="c18" href="#h.gxr6vdbt6q0j">2. </a></span><span class="c17">City Brain / Smart Nation: Internet of Things (IoT), Cloud/Edge/Fog Computing</span></p><p class="c47"><span class="c8"><a class="c18" href="#h.1u7uvgc0zbwu">3. Security / Privacy</a></span></p><p class="c47"><span class="c8"><a class="c18" href="#h.e16n83bp0547">4. 6G Wireless Networks (including AI and Intelligent Reflecting Surfaces)</a></span></p><p class="c7"><span class="c2"></span></p><h1 class="c34 c33" id="h.ckz6p59xskk8"><span class="c16">1. Artificial Intelligence (AI)</span></h1><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.1lajoyme23kw"><span class="c5">1.1 Autonomous Deep Learning for Continual Learning in Complex Data Stream Environment</span></h2><p class="c7"><span class="c2"></span></p><p class="c31"><span class="c2">Researcher: Andri Ashfahani</span></p><p class="c7"><span class="c2"></span></p><p class="c3"><span class="c2">The goal of this research is to step-by-step solve complex data stream problems in continual learning environments using deep neural networks (DNNs). There are four articles in this research. Each of these articles presents a new method for data stream learning using DNN. Each of these articles demonstrates the effectiveness of the proposed method in the streaming environment. The proposed methods are applicable and in some cases have been applied to other kinds of tasks, i.e, transfer learning and control algorithms, but this research does not explore such applications.</span></p><p class="c3 c19"><span class="c2"></span></p><h3 class="c43 c33" id="h.t0a0ixluvkey"><span class="c21">1.1.1 Incremental Learning of Deep Neural Networks for Evolving Data Streams</span></h3><p class="c3"><span class="c2">In the first article, the problem of how to incrementally increase the network capacity in respect to problem complexity is handled. We proposed incremental learning of DNNs for Evolving Data Streams, namely Autonomous Deep Learning (ADL). It characterizes flexible network structure where its hidden nodes and hidden layers can be incrementally constructed from scratch. The network significance (NS) formula derived from bias-variance tradeoff is utilized to control the network complexity. This formula works by monitoring the possible underfitting and overfitting situation of a DNN. To further identify loss of generalization power, Drift detection scenario (DDS) is carried out to signal a real drift situation. This triggers the construction of a new hidden layer. The concept of different depth network structure is put forward to specifically combat the catastrophic forgetting problem because of hidden layer evolution. That is, ADL accommodates every hidden layer output in the final classification decision such that it is able to flexibly retain the constructed knowledge in the previous layers. The learning policy of ADL is depicted in Fig. 1. ADL succeeds at solving classification problems which is simulated under prequential test-then-train protocol. The different depth network structure of ADL, however, is only viable for classification problems and is not fully suitable for other implementation scenarios. Note that ADL is able to put different emphasis on every hidden layer based on the accuracy matrix. In the control system and regression problems, for instance, the accuracy matrix cannot be obtained as those problems usually employ mean squared error (MSE) loss as the objective function. It highlights the importance of Multi-layer Perceptron (MLP)-like network structure as it is more applicable in other scenarios.</span></p><p class="c3"><span>&nbsp;</span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 315.50px; height: 201.62px;"><img alt="" src="images/image26.png" style="width: 315.50px; height: 201.62px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c2">Figure 1:The learning policy of ADL</span></p><p class="c3 c19"><span class="c2"></span></p><h3 class="c43 c33" id="h.rekmulcedhbu"><span class="c21">1.1.2 Automatic Construction of Multi-layer Perceptron (MLP) from Streaming Examples </span></h3><p class="c3"><span class="c2">In the second article, we explore the strategy to expand the capacity of MLP structure in respect to the problem complexity. We formalize this method as a Neural Network with Dynamically Evolved Capacity (NADINE). The main bottleneck to evolve a MLP structure is the loss of performance whenever a new hidden layer is added. We called this problem a catastrophic forgetting because of structural evolution. The major cause of this is the random initialization of the newly added layer. This problem is mitigated by using a sample and replay mechanism. It is understood that retaining samples and retraining the model should be avoided in the context of data stream learning. Because of that reason, a method to collect important samples, namely adaptive memory, from the streaming data is developed. The collected samples are then used to retrain the network whenever there is a real drift confirmed by DDS. It is worth mentioning that the size of the important samples can be maintained and the retraining process is only conducted whenever there is a new layer. Because every hidden layer is constructed in different concepts, it is important to govern the amount of updates in each hidden layer according to its relevance to the output. The soft-forgetting strategy is proposed to handle this objective where it translates the correlation of each hidden layer and output to independent learning raters for every hidden layer. Finally, the hidden node evolving mechanism utilizes the similar method introduced in ADL. The learning policy of NADINE is presented in Fig. 2, red box indicates the additional learning strategies compared to the previous article. NADINE is tested on both classification and regression problems where it is better than other benchmarks. ADL and NADINE, however, do not fully consider the fact that data come without labels because it has no unsupervised learning mechanism to handle concept drifts exploiting unlabeled samples.</span></p><p class="c3"><span>&nbsp;</span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 325.00px; height: 218.64px;"><img alt="" src="images/image18.png" style="width: 325.00px; height: 218.64px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c2">Figure 2:The learning policy of NADINE</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><h3 class="c43 c33" id="h.glrc9bz4cl67"><span class="c21">1.1.3 Incremental Learning of Denoising Autoencoder for Evolving Data Streams</span></h3><p class="c3"><span class="c2">In the third article, we revisit the concept of denoising autoencoders (DAE) as a generative training mechanism which addresses the random initialization problem of DNNs. From the viewpoint of continual learning in the streaming environment, it encourages DNNs to adapt to concept changes while waiting the labeling process. Being motivated by these facts, we proposed deep evolving denoising autoencoder (DEVDAN). The main feature of DEVDAN lies in the coupled-generative-discriminative-learning phases which enable DEVDAN to exploit both labeled and unlabeled samples. The evolving trait of DEVDAN is carried out in both phases attempting to handle concept changes with or without label. We put forward DAE to handle newly incoming data in an unsupervised manner. In this phase, the evolving mechanism is controlled by the NS formula. Unlike ADL, the NS formula in the generative phase is derived from the squared reconstruction error. After the labeling process is finished, the discriminative phase is executed to improve the generalization power with labeled samples. The hidden nodes growing and pruning mechanism is governed by the same NS formula as for ADL. The two training phases are executed alternately whenever a data batch comes creating a continual learning cycle. The learning policy of DEVDAN can be observed in Fig. 3. DEVDAN offers improvement over ADL in some cases, especially in a situation where the number of labeled data is less than the number of unlabeled data. Nevertheless, DEVDAN does not involve any learning mechanism which specifically addresses the lack of labeled data.</span></p><p class="c3"><span>&nbsp;</span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 297.36px; height: 235.50px;"><img alt="" src="images/image9.png" style="width: 297.36px; height: 235.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c2">Figure 3:The learning policy of DEVDAN</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><h3 class="c33 c43" id="h.qlbh1tx2xg0g"><span class="c21">1.1.4 Weakly Supervised Deep Learning Approach in Streaming Environments </span></h3><p class="c3"><span class="c2">The general trend of deep learning research changed dramatically during the midst of the work on this thesis with the presentation from Yann LeCun in which he stated that unsupervised, semi-supervised and self-supervised learning problems are the major challenges of AI for the next decade. Semi-supervised and self-supervised learning behaves similarly to supervised learning in which it learns a function from input-output pairs of data. However, they have additional features to address the lack of labeled samples. That is, they can automatically generate labels from the input data. In the viewpoint of evolving data streams, this can be adopted to circumvent one of major limitations in data streams. That is, all true class labels are not immediately available after receiving the data. The third paper in this thesis presents a self-evolving deep neural network, namely Parsimonious Network (ParsNet), as a solution of weakly-supervised data stream problem. A self-labeling strategy with hedge (SLASH) is proposed in which its auto-correction mechanism copes with \textit{the accumulation of mistakes} significantly affecting the model&#39;s generalization. ParsNet is developed from a closed-loop configuration of the self-evolving generative and discriminative training processes similar to DEVDAN. The learning policy is illustrated in Fig. 4. When tested on benchmark datasets, ParsNet outperforms prominent algorithms with substantial margin in the high-dimensional data streams and infinite delay simulation protocol.</span></p><p class="c3"><span>&nbsp;</span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 301.00px; height: 267.13px;"><img alt="" src="images/image5.png" style="width: 301.00px; height: 267.13px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c9"><span class="c2">Figure 4:The learning policy of ParsNet</span></p><p class="c9 c19"><span class="c2"></span></p><p class="c3"><span class="c29">Pratama, Mahardhika, </span><span class="c29 c57">Ashfahani, Andri,</span><span class="c29">&nbsp;and Abdul Hady. &quot;Weakly supervised deep learning approach in streaming environments.&quot; In </span><span class="c29 c54">2019 IEEE International Conference on Big Data (Big Data)</span><span class="c29">, pp. 1195-1202. IEEE, 2019.</span></p><p class="c7"><span class="c2"></span></p><p class="c3"><span class="c2">Conclusions and Future Works.</span></p><p class="c3"><span class="c2">Finally, we draw conclusions from several works that have been done. In future work, we are interested in investigating the fully unsupervised for continual learning in data stream environments. The ideas from state-of-the-arts unsupervised learning literature will be incorporated to find the effective algorithm for this scenario. Separately, we are also interested in developing methodologies to incrementally construct convolutional neural networks (CNNs) from scratch. It has a lot of components and hyper-parameters, i.e, convolutional layer, fully connected layer, number of layers, number of filters, filter size etc, making it difficult to construct a CNN for a particular problem. Most methodologies to find the optimal CNN architecture are based on meta-learning and reinforcement learning which require resources. We will try to develop the continual evaluation methods to assess the CNN performance which are then used to control the automatic construction of CNN. It is expected that the result possesses less computational complexity as it is purely built upon a data driven approach which can be executed in a single-pass learning fashion.</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.ucnzv4to5n0x"><span class="c5">1.2 Computer Vision (CV)</span></h2><p class="c7"><span class="c2"></span></p><h3 class="c43 c33" id="h.2nwjqem02qge"><span class="c21">1.2.1 Autonomous Convolutional Neural Networks (AutoCNN) </span></h3><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 650.67px;"><img alt="" src="images/image22.png" style="width: 624.00px; height: 650.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c43 c33" id="h.pt9dprgzd9s3"><span class="c21">1.2.2 Computer Vision (CV) for Construction</span></h3><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 440.00px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c53 c33" id="h.ondb4qvbq0bk"><span class="c21">1.2.3 Physical rule-based reflection removal with camera calibration</span></h3><p class="c7"><span class="c2"></span></p><p class="c31"><span class="c2">Researcher: Jinnan Chen</span></p><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 633.50px; height: 262.94px;"><img alt="" src="images/image24.png" style="width: 633.50px; height: 262.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c2"></span></p><p class="c3"><span class="c2">Separating transmission image from a single reflection-contaminated image is an ill-posed computer vision problem which has been studied for a long time in computer vision community. In order to make this problem more trackable, we aim to jointly remove the reflection part and calibrate the orientation of glass and the field of view (FoV) of the camera by using a reflection amplitude coefficient map as a calibration cue. We synthesize the paired training data in a physical rule-based way and thus encode these geometric constraints into the learnable parameters of our image separation network. For camera calibration, different from existing methods, our proposed solution is agnostic to image contents so it is more robust for different real-world scenarios. We proposed a learning-based method that fully exploits all entries of the reflection amplitude coefficient map to estimate the glass plane orientation and FoV of the camera. Besides, we also collect a dataset containing 320 samples as well as their camera parameters for evaluation. The experiments demonstrate that our method not only facilitates the performance of single image reflection removal but also contributes to solve single image camera calibration in such cases. What&rsquo;s more, we demonstrate our by-product output helps alleviate another ill-posed problem of estimating the panorama from a single image.</span></p><h2 class="c39 c33" id="h.r12f34o2547p"><span class="c5">&nbsp;</span></h2><h2 class="c39 c33" id="h.8jf2rhx3b5yo"><span class="c5">1.3 ?</span></h2><p class="c7"><span class="c2"></span></p><p class="c31"><span class="c2">Researcher: A</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.8h7r4ihhfag2"><span class="c5">1.4 Adversarial Machine Learning</span></h2><p class="c7"><span class="c2"></span></p><p class="c31"><span>Researcher: </span><span>Bai Tao</span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><h3 class="c43 c33" id="h.v694hg5oejv9"><span class="c21">1.4.1 AI-GAN: Attack-Inspired Generation of Adversarial Examples</span></h3><p class="c14"><span class="c2"></span></p><p class="c52"><span class="c2">In this paper, we propose Attack-Inspired GAN (AI-GAN) with a different training strategy to solve this problem. AI-GAN is a two-stage method, in which we use projected gradient descent (PGD) attack to inspire the training of GAN in the first stage and apply standard training of GAN in the second stage. Once trained, the Generator can approximate the conditional distribution of adversarial instances and generate imperceptible adversarial perturbations given different target classes. We conduct experiments and evaluate the performance of AI-GAN on MNIST and CIFAR-10. Compared with AdvGAN, AI-GAN achieves higher attack success rates with similar perturbation magnitudes.</span></p><p class="c15"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 424.00px;"><img alt="" src="images/image29.png" style="width: 624.00px; height: 424.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c14"><span class="c2"></span></p><p class="c35"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 440.00px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 440.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c29">Bai, Tao, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, and Bo Li. &quot;AI-GAN: Attack-Inspired Generation of Adversarial Examples.&quot; arXiv preprint arXiv:2002.02196 (2020).</span></p><p class="c15"><span class="c22">&nbsp;</span></p><h3 class="c15 c33" id="h.q96wh0fpbwrz"><span class="c21">1.4.2 Generating Adversarial yet Inconspicuous Patches with a Single Image</span></h3><p class="c52"><span class="c2 c41">Deep neural networks have been shown vulnerable to adversarial patches, where exotic patterns can result in models wrong prediction. Nevertheless, existing approaches to adversarial patch generation hardly con-sider the contextual consistency between patches and the image background, causing such patches to be easily detected and adversarial attacks to fail. On the other hand, these methods require a large amount of data for training, which is computationally expensive. To overcome these challenges, we propose an approach to generate adversarial yet inconspicuous patches with one single image. In our approach, adversarial patches are produced in a coarse-to-fine way with multiple scales of generators and discriminators. Contextual information is encoded during the Min-Max training to make patches consistent with surroundings. The selection of patch location is based on the perceptual sensitivity of victim models. Through extensive experiments, our approach shows strong attacking ability in both the white-box and black-box setting. Experiments on saliency detection and user evaluation indicate that our adversarial patches can evade human observations, demonstrating the inconspicuousness of our approach. Lastly, we show that our approach preserves the attack ability in the physical world.</span></p><p class="c35"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c14"><span class="c22"></span></p><p class="c35"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 277.33px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 277.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c15"><span class="c29">Luo, Jinqi, Tao Bai, Jun Zhao, and Bo Li. &quot;Generating Adversarial yet Inconspicuous Patches with a Single Image.&quot; arXiv preprint arXiv:2009.09774 (2020).</span></p><p class="c15"><span class="c46 c41">&nbsp;</span></p><h3 class="c15 c33" id="h.e5fcaipd0l27"><span class="c21">1.4.3 Feature Distillation With Guided Adversarial Contrastive Learning</span></h3><p class="c52"><span class="c2 c41">Deep learning models are shown to be vulnerable to adversarial examples. Though adversarial training can enhance model robustness, typical approaches are computationally expensive. Recent works proposed to transfer the robustness to adversarial attacks across different tasks or models with soft labels. Compared to soft labels, the feature contains rich semantic information and holds the potential to be applied to different downstream tasks. In this paper, we propose a novel approach called Guided Adversarial Contrastive Distillation (GACD), to effectively transfer adversarial robustness from teacher to student with features. We first formulate this objective as contrastive learning and connect it with mutual information. With a well-trained teacher model as an anchor, students are expected to extract features similar to the teacher. Then considering the potential errors made by teachers, we propose sample reweighted estimation to eliminate the negative effects from teachers. With GACD, the student not only learns to extract robust features, but also captures structural knowledge from the teacher. By extensive experiments evaluating over popular datasets such as CIFAR-10, CIFAR-100 and STL-10, we demonstrate that our approach can effectively transfer robustness across different models and even different tasks, and achieve comparable or better results than existing methods. Besides, we provide a detailed analysis of various methods, showing that students produced by our approach capture more structural knowledge from teachers and learn more robust features under adversarial attacks.</span></p><p class="c35"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 465.00px; height: 356.00px;"><img alt="" src="images/image25.png" style="width: 465.00px; height: 356.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 384.00px;"><img alt="" src="images/image28.png" style="width: 624.00px; height: 384.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c1 c41">&nbsp;</span></p><p class="c15"><span class="c29">Bai, Tao, Jinnan Chen, Jun Zhao, Bihan Wen, Xudong Jiang, and Alex Kot. &quot;Feature Distillation With Guided Adversarial Contrastive Learning.&quot; arXiv preprint arXiv:2009.09922 (2020).</span></p><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.wn19rhcbp828"><span class="c5">1.5 Reinforcement Learning</span></h2><p class="c31"><span class="c2">See </span></p><p class="c40"><span class="c17"><a class="c18" href="#h.pr1u9o1lg4wa">4.1.1 Deep reinforcement learning based intelligent reflecting surface for secure wireless communications</a></span></p><p class="c40"><span class="c17"><a class="c18" href="#h.g2npmva170a2">4.1.2 Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach</a></span></p><p class="c7"><span class="c2"></span></p><h2 class="c33 c39" id="h.j3j7w5zedugr"><span class="c5">1.6 Federated Learning</span></h2><h3 class="c53 c33" id="h.8kqjxylm37b6"><span class="c21">1.6.1 Why federated learning is right for you</span></h3><ul class="c13 lst-kix_t2no3e9jpit1-0 start"><li class="c3 c25"><span class="c0">Federated learning is a booming field, both in academia and in industry!</span></li><li class="c3 c25"><span class="c2">Federated learning was invented by Google in 2017. Federated learning will have impacts similar to those of other Google inventions: TensorFlow, MapReduce, etc.</span></li><li class="c3 c25"><span class="c0">Many high-tech companies are following Google to do federated learning. These companies include Apple, Amazon, Facebook, Microsoft, Alibaba, Tencent, WeBank, ByteDance, SenseTime &hellip;</span></li><li class="c3 c25"><span>The first academic paper on federated learning, published by Google in 2017, received over 1000 citations in July 2020:<br></span><span class="c32"><a class="c18" href="https://www.google.com/url?q=http://proceedings.mlr.press/v54/mcmahan17a.html&amp;sa=D&amp;ust=1602411110606000&amp;usg=AOvVaw3-laUtYlN8I0tvvGG2ckVN">http://proceedings.mlr.press/v54/mcmahan17a.html </a></span><span class="c32"><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/1602.05629&amp;sa=D&amp;ust=1602411110606000&amp;usg=AOvVaw3kLTnXj3U5GMgdd4HJ_o0f">&nbsp;</a></span></li><li class="c3 c25"><span>58 big names in academia (MIT, Stanford, CMU, Berkeley, Princeton, Cornell, NTU, UIUC, EPFL) and industry (Google, WeBank) together uploaded a 100-page paper to arXiv in December 2019: </span><span class="c32"><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/1912.04977&amp;sa=D&amp;ust=1602411110606000&amp;usg=AOvVaw36SjvKTQzNQ9fTVFJAAxol">https://arxiv.org/abs/1912.04977<br></a></span><span class="c2">You know federated learning is hot when you see this. Nothing like this happened for other topics before. This paper has been cited for over 100 times in less than 6 months.</span></li><li class="c3 c25"><span class="c2">NTU is a hotbed for federated learning research. </span></li><li class="c3 c25"><span class="c2">Turing Award Winners and Academicians from National Academy of Science/Engineering are working on federated learning. </span></li><li class="c3 c25"><span>Papers on federated learn</span><span class="c30">ing have won numerous best paper awards in academic conferences and journals. </span></li></ul><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 320.00px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 320.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 498.00px; height: 275.00px;"><img alt="" src="images/image35.png" style="width: 498.00px; height: 275.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c33 c53" id="h.k5hj3xhgheo6"><span class="c21">1.6.2 Privacy-Preserving Federated learning-based UAV-enabled wireless networks</span></h3><p class="c44"><span class="c2">Deploying UAVs as flight BSs is able to flexibly collect data and implement AI model training for ground devices, but it is impractical for a large number of devices to transmit their &nbsp;raw data to UAV servers due to the privacy concern and limited communication resources for data transmission. Moreover, as the energy capacity, storage, and computational ability of UAVs are limited, it is still challenging for UAVs to process/train a large amount of raw data. In face of the challenges, federated learning (FL) emerges as a promising paradigm aiming to protect device privacy by enabling devices to train AI models locally without sending their raw data to a server. Instead of training AI models at the data server, FL enables devices to execute local training on their own data, which generally uses the gradient descent optimization method.</span></p><p class="c44 c55"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 535.00px; height: 221.00px;"><img alt="" src="images/image33.png" style="width: 535.00px; height: 221.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c44"><span class="c2">Fig. 11. Federated learning-based UAV-enabled wireless networks.</span></p><p class="c44"><span class="c2">&nbsp;</span></p><p class="c20"><span class="c2">In the FL instance, as illustrated in Fig. 11, each device has its own personal dataset and it is willing to upload a part of inflammation (i.e., AI model parameters) to its associated UAV server in a privacy-preserving manner. In addition, devices involved in a common computing task (e.g., training a classification model) are more likely to work with others together to finish the task collaboratively, by adopting AI techniques. These devices will update their own local AI model parameters to associated UAV servers for global model aggregation. Each device processes the local model training based on its local raw dataset without sharing the raw data with other devices, to protect the privacy of data providers. After completing local model training, each device will send its local model parameters to its associated UAV server by the uplink communication channel, and the corresponding UAV server aggregates the local parameters from the selected devices before broadcasting the aggregated global parameters to the devices by the downlink communication channel.</span></p><p class="c6"><span class="c2">In Fig. 12, we compare the accuracy performance versus the number of global rounds and wall-clock time for different FL approaches, where several devices are set as low-quality participants. The low-quality participants are with low communication and computation capabilities, and even have low-quality training parameters. From Fig. 12(a), we can observe that both the AFL and SFL approaches with device selection require about 25 global rounds to achieve an accuracy of 90.0%, and both of them have similar convergence speed and accuracy performance. However, at each global round, SFL has to wait until all the selected devices respond, while AFL only needs a number of selected devices&#39; response to move on to the next round which decreases the aggregation completion time during the learning process as shown in Fig. 12(b). In addition, both the AFL and SFL approaches with device selection achieve higher accuracy and convergence speed than those of the AFL approach without device selection. The results illustrate that the proposed device selection scheme can prevent low-quality devices from affecting the learning accuracy, and enhances the system performance significantly. </span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c6"><span>&nbsp; </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 295.00px; height: 267.00px;"><img alt="" src="images/image6.png" style="width: 295.00px; height: 267.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 293.00px; height: 268.00px;"><img alt="" src="images/image21.png" style="width: 293.00px; height: 268.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c2">Fig. 12. Accuracy comparison versus (a) number of global communication rounds and (b) wall-clock time.</span></p><p class="c6"><span class="c2">From Fig. 12(b), we can see that the accuracy of all approaches improves with the increase of the wall-clock time. However, by comparing different approaches, the proposed AFL approach with device selection outperforms the other two approaches in terms of both the convergence speed and accuracy. The reason lies in the fact that the AFL approach without device selection may enable the low-quality devices to participate in the FL model aggregation, where the low-quality model parameters decrease the overall accuracy, as well as devices with low communication and computation capacities need more time to complete the model aggregation. In addition, the SFL approach with device selection has to wait for all selected devices to complete their local model parameters update, among which there may require long computation time due to low computation capability. Consequently, each global communication round of the SFL approach with device selection requires more time to finish model aggregation, and hence its accuracy performance slowly improves with the increase of wall-clock time. The results from Fig. 12 demonstrate that the proposed AFL approach with device selection is capable of improving both the convergence speed and aggregation accuracy performance. &nbsp;</span></p><p class="c31"><span>[7]</span><span class="c36">&nbsp;</span><span class="c2">Helin Yang, Zehui Xiong, Jun Zhao, Kwo Yan Lam, Sumei Sun, and Liang Xiao, &ldquo;Privacy-Preserving Federated Learning for UAV-Enabled Networks: Learning-Based Joint Scheduling and Resource Management,&rdquo; submitted to IEEE Journal on Selected Areas in Communications by Oct. 2020. &nbsp;</span></p><h1 class="c34 c33" id="h.gxr6vdbt6q0j"><span class="c16">2. City Brain / Smart Nation: Internet of Things (IoT), Cloud/Edge/Fog Computing</span></h1><ul class="c13 lst-kix_1r9d50j0cire-0 start"><li class="c3 c25"><span class="c2">Artificial Intelligence of Things (AIoT) with federated learning, deep learning, reinforcement learning, adversarial machine learning, etc.</span></li><li class="c3 c25"><span class="c2">Internet of Things (IoT)</span></li><li class="c3 c25"><span class="c2">Cloud/Edge/Fog Computing</span></li><li class="c3 c25"><span class="c2">Blockchain </span></li><li class="c3 c25"><span class="c2">Security and Privacy</span></li></ul><p class="c31"><span class="c26">&nbsp; </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 537.33px;"><img alt="" src="images/image8.png" style="width: 624.00px; height: 537.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c26">&nbsp; &nbsp;</span><span class="c46">Figure 1. A Hierarchical View of City Brain / Smart Nation.</span><span class="c26"><br> &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 408.00px;"><img alt="" src="images/image19.png" style="width: 624.00px; height: 408.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c26">&nbsp; &nbsp;</span><span class="c46">Figure 2. A View of City Brain / Smart Nation Highlighting Industrial Applications.</span><span class="c26"><br> &nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 658.67px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 658.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c26">&nbsp; &nbsp;</span><span class="c46">Figure 3. Industrial Applications of City Brain / Smart Nation.</span><span class="c26"><br></span></p><h1 class="c34 c33" id="h.1u7uvgc0zbwu"><span class="c16">3. Security / Privacy</span></h1><h2 class="c39 c33" id="h.nno70ggx2xef"><span class="c5">3.1 Adversarial Machine Learning</span></h2><p class="c28"><span>See </span><span class="c17"><a class="c18" href="#h.8h7r4ihhfag2">1.4 Adversarial Machine Learning</a></span></p><h2 class="c39 c33" id="h.yn4lu1vquq0"><span class="c5">3.2 Secure Communications</span></h2><p class="c28"><span class="c2">See </span></p><p class="c40"><span class="c17"><a class="c18" href="#h.pr1u9o1lg4wa">4.1.1 Deep reinforcement learning based intelligent reflecting surface for secure wireless communications</a></span></p><p class="c40"><span class="c17"><a class="c18" href="#h.g2npmva170a2">4.1.2 Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach</a></span></p><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.mnsfxz2zmwbm"><span class="c5">3.3 Privacy-Preserving Federated Learning</span></h2><p class="c31"><span>See </span><span class="c17"><a class="c18" href="#h.k5hj3xhgheo6">1.6.2 Federated learning-based UAV-enabled wireless networks</a></span></p><p class="c7"><span class="c2"></span></p><h2 class="c39 c33" id="h.1ox7xiyfjc8o"><span class="c5">3.4 Differential Privacy for Fog Computing</span></h2><p class="c31"><span>Researcher: </span><span>Mengmeng Yang</span><span class="c23">&nbsp;</span></p><p class="c31"><span class="c23">&nbsp;</span></p><p class="c3"><span class="c2">Secure Hot Path Crowdsourcing with Local Differential Privacy under Fog Computing Architecture</span></p><p class="c3"><span class="c2">For a traditional crowdsourcing system, the server interacts with the participants directly after receiving the tasks from the requester. However, offloading the data to the cloud introduces unforeseeable delay and heavy communication burden, especially when multiple interactions are needed. A better alternative solution is to take advantage of the nearby infrastructures or devices to process the data and send the processed data back to the cloud. This process is called edge computing, also known as fog computing. Though edge computing enhances crowdsourcing, the collected data can also be used by the adversary to make sensitive inferences. The traditional solutions rely on the premise that the fog node is trusted and a series of privacy strategies are performed by the fog node on top of the user&rsquo;s real data. However, the fog node may not be trusted either. Therefore, the information needs to be protected locally by perturbing it before it leaves the user&rsquo;s devices. In this paper, we consider the location privacy problem for hot path statistics in the crowdsourcing system under fog computing architecture. To provide a much more accurate statistic while preserving the user&rsquo;s location information locally, we proposed a novel solution that combines both local differential privacy technology and secret sharing technology.</span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 260.50px; height: 230.28px;"><img alt="" src="images/image23.png" style="width: 260.50px; height: 230.28px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c1"></span></p><p class="c9"><span class="c1">Framework </span></p><p class="c3"><span class="c2">(1)The proposed method can achieve a much higher accuracy even if the privacy budget is quite small. The error of the proposed method only comes from the sampling processes (e.g. worker selection and node selection), which are controlled by privacy budget and sample rate respectively. Even when the privacy budget is very small, we can still expect to have around half of the participating workers to contribute to the statistical count by adjusting the parameter. (2)The proposed method can achieve a good performance even when a limited number of workers participate. This is because all the selected workers report the true value through secret sharing instead of a perturbed value to the fog node. As we mentioned, the error only comes from the sampling processes, which are independent of the data dimension and have a much smaller statistical variance.</span></p><p class="c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 170.67px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 170.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c2"></span></p><p class="c7"><span class="c23"></span></p><h1 class="c33 c34" id="h.e16n83bp0547"><span class="c16">4. 6G Wireless Networks (including AI and Intelligent Reflecting Surfaces)</span></h1><p class="c7"><span class="c2"></span></p><p class="c31"><span>Researcher: </span><span class="c23">Yang Helin &nbsp;</span></p><p class="c6 c19"><span class="c51 c61"></span></p><h2 class="c6 c33" id="h.g2t88we5sxq9"><span>4.1 Intelligent Reflecting Surfaces (IRS) for 6G Wireless Networks</span></h2><p class="c6"><span class="c2">A new paradigm, called intelligent reflecting surface (IRS), has been proposed as a promising technique to achieve high spectrum efficiency and energy efficiency, and enhance secrecy rate in the fifth generation (5G) and beyond wireless communication systems. In particular, IRS is a uniform planar array which is comprised of a number of low-cost passive reflecting elements, where each of elements adaptively adjusts its reflection amplitude and/or phase to control the strength and direction of the electromagnetic wave, hence IRS is capable of enhancing and/or weakening the reflected signals at different users. &nbsp;As a result, the reflected signal by the IRS can increase the received signal at legitimate users while suppressing the signal at the eavesdroppers. Hence, from the PLS perspective, some innovative studies have been recently devoted to performance optimization for IRS-aided secure communications.</span></p><h3 class="c6 c33" id="h.pr1u9o1lg4wa"><span>4.1.1</span><span class="c10">&nbsp;</span><span class="c21">Deep reinforcement learning based intelligent reflecting surface for secure wireless communications</span></h3><p class="c6"><span class="c2">We consider an IRS-aided secure communication system, as shown in Fig. 1, where the BS is equipped with N antennas to serve K single-antenna legitimate mobile users (MUs) in the presence of M single-antenna eavesdroppers. An IRS with L reflecting elements is deployed in the system to assist secure wireless communications from the BS to the MUs. The IRS is equipped with a controller to coordinate with the BS. For the ease of practical implementation, the maximal reflection without power loss at the IRS is considered since the reflecting elements are designed to maximize the reflected desired signal power to the MUs. In addition, unauthorized eavesdroppers aim to eavesdrop any of the data streams of the MUs. &nbsp;Hence, the use of reflecting beamforming at IRS is also investigated to improve the achievable secrecy rate at the MUs while suppressing the wiretapped data rate at the eavesdroppers. In addition, we explicitly state that the eavesdroppers cannot collide. &nbsp;</span></p><p class="c27"><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 344.00px; height: 239.00px;"><img alt="" src="images/image20.png" style="width: 344.00px; height: 239.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c46">Fig. 1. IRS-aided secure communication under multiple eavesdroppers.</span><span class="c2">&nbsp;</span></p><p class="c6 c19"><span class="c2"></span></p><p class="c6"><span class="c2">Considering the fact that the IRS-aided secure communication system has high-dimensional and high-dynamical characteristics according to the system state that is defined in and uncertain CSI, we propose a deep PDS-PER learning based secure beamforming approach, as shown in Fig. 2, where PDS-learning and PER mechanisms are utilized to enable the learning agent to learn and adapt faster in dynamic environments. In detail, the agent utilizes the observed state (i.e, CSI, previous secrecy rate, QoS satisfaction level), the feedback reward from the environment as well as the historical experience from the replay buffer to train its learning model. After that, the agent employs the trained model to make decision beamforming matrices based on its learned policy. The procedures of the proposed learning based secure beamforming are provided in the following subsections. &nbsp;</span></p><p class="c27"><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 363.00px; height: 239.00px;"><img alt="" src="images/image10.png" style="width: 363.00px; height: 239.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 2. Deep PDS-PER learning based beamforming for IRS-aided secure communications.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c6"><span class="c2">In Fig. 3, the achievable secrecy rate and QoS satisfaction level performance of all approaches are evaluated through changing the IRS elements. For the secure beamforming approaches assisted by the IRS, their achievable secrecy rates and QoS satisfaction levels significantly increase with the number of the IRS elements. The improvement results from the fact that more IRS elements, more signal paths and signal power can be reflected by the IRS to improve the received SINR at the MUs but to decrease the received SINR at the eavesdroppers. In addition, the performance of the approach without the IRS remains constant under the different numbers of the IRS elements. From Fig. 3(a), it is found that the secrecy rate of the proposed learning approach is higher than those of the Baseline 1 and DQN approaches, especially, their performance gap also obviously increases with $L$, this is because that with more reflecting elements at the IRS, the proposed deep PDS-PER learning based secure communication approach becomes more flexible for optimal phase shift (reflecting beamforming) design and hence achieves higher gains. In addition, from Fig. 3(b) compared with the Baseline 1 and DQN approaches, as the reflecting elements at the IRS increases, we observe that the proposed learning approach is the first one who attains 100% QoS satisfaction level. These superior achievements are based on the particular design of the QoS-aware reward function for secure communication.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 305.00px; height: 278.00px;"><img alt="" src="images/image3.png" style="width: 305.00px; height: 278.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 299.00px; height: 279.00px;"><img alt="" src="images/image15.png" style="width: 299.00px; height: 279.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 3. Performance comparisons versus the number of IRS elements.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><h3 class="c6 c33" id="h.g2npmva170a2"><span class="c24">4.1.2</span><span class="c10 c24">&nbsp;</span><span class="c21">Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach</span></h3><p class="c6"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As shown in Fig. 4, this paper considers an IRS-assisted communication system, which consists of one BS with N antennas and K single-antenna legitimate user equipments (UEs) located at the cell-edge. The IRS composed of M reflecting elements is deployed to provide additional communication links so as to improve the performance for the UEs over a given frequency band. The direct communication links of cell-edge UEs may suffer high signal attenuation and these links are severely blocked by obstacles when these UEs are located in dead zones. In addition, as illustrated in Fig. 4, a malicious (or unfriendly) multi-antenna jammer is located near the &nbsp;UEs who attempt to interfere with the &nbsp;transmissions by sending faked or replayed jamming signal for the UEs via &nbsp;antennas, in order to degrade the &nbsp;communication performance. In this case, deploying the IRS can effectively enhance the desired signal power and mitigate the jamming interference generated from the jammer by designing the reflecting beamforming at the IRS. &nbsp;</span></p><p class="c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 298.00px; height: 142.00px;"><img alt="" src="images/image31.png" style="width: 298.00px; height: 142.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 4. Illustration of an IRS-assisted communication system against a multi-antenna jammer.</span></p><p class="c6"><span class="c2">&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In order to obtain the optimal anti-jamming policy against smart jamming, we propose a fast fuzzy WoLF-PHC-based joint power allocation and reflecting beamforming for IRS-assisted communication systems, as shown in Fig. 5, where WoLF-PHC is utilized to enable the learning agent to learn and adapt faster in dynamic uncertain environments, and FSA is used to enable Q-Learning to represent the system states with a fixed number of aggregate states and represent continuous state spaces as discrete. In the IRS-assisted system, the learning agent observes a system state and receives an instantaneous reward by interacting with the environment. Then, such information is leveraged to train the learning model to choose the anti-jamming policy with the maximum Q-function value. After that, according to the selected policy, the action is chosen to make decisions in terms of power allocation and reflecting beamforming. The procedures of the proposed learning based decision making approach are provided in the following analysis. &nbsp;</span></p><p class="c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 318.00px; height: 191.00px;"><img alt="" src="images/image27.png" style="width: 318.00px; height: 191.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 5. Fuzzy WoLF-PHC-based anti-jamming policy for IRS-assisted systems.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c6"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig. 6 compares the performance of the four approaches for different reflecting elements number. It can be seen that, except the optimal PA approach without IRS, the performance of all IRS-based approaches increases with $M$, and greatly outperforms the optimal PA approach without IRS. The reason is that the IRS has the ability to support higher degrees of freedom for performance optimization, resulting in the great performance gains obtained by employing the IRS against smart jamming over the traditional system without IRS. Specifically, when &nbsp;M = 20, the system achievable rate gain of the proposed learning approach over the optimal PA approach without IRS is only about 2.36 bits/s/Hz, while this value is improved to 12.21 bits/s/Hz when &nbsp;M = 100. In addition, by deploying the IRS, the SINR protection level is significantly improved compared with the optimal PA approach without IRS assistance. Such performance improvement results from the fact that higher power can be achieved at the IRS by increasing M, and a higher reflecting beamforming gain is achieved to design the IRS phase shifts to improve the received desired signal as well as mitigate the jamming interference from the smart jammer by increasing M. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c6"><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 299.00px; height: 271.00px;"><img alt="" src="images/image34.png" style="width: 299.00px; height: 271.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 294.00px; height: 269.00px;"><img alt="" src="images/image2.png" style="width: 294.00px; height: 269.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 6 Performance comparisons versus the number of IRS elements.</span></p><p class="c6"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In addition, from Fig. 6(a), we can also observe that the achievable rate of the proposed learning approach outperforms both the fast Q-Learning and Baseline 1 approaches, and especially, the performance gap significantly increases with M. At the same time, Fig. 6(b) shows that, as the reflecting elements increases, the proposed learning approach is the first one can achieve 100% SINR protection level compared with other approaches. This is because deploying more reflecting elements, the proposed fuzzy WoLF-PHC-learning based joint power allocation and reflecting beamforming approach becomes more flexible for optimal phase shift (reflecting beamforming) design and hence achieves the higher performance gain. These results also show that employing IRS into wireless communications improves the anti-jamming communication performance against smart jamming.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c20"><span>[1]</span><span class="c36">&nbsp;</span><span class="c2">Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, and Liang Xiao, &ldquo;Deep reinforcement learning based intelligent reflecting surface for secure wireless communications,&rdquo; IEEE Transactions on Wireless Communications. (Accepted) DOI: 10.1109/TWC.2020.3024860.</span></p><p class="c20"><span>[2]</span><span class="c36">&nbsp; &nbsp;</span><span class="c2">Helin Yang, Yang Zhao, Zehui Xiong, Jun Zhao, Dusit Niyato, Kwok-Yan Lam, and Qingqing Wu, &ldquo;Deep reinforcement learning based intelligent reflecting surface for secure wireless communications&rdquo; IEEE Global Communications Conference (GLOBECOM), 2020, Taipei, Taiwan, Dec. 2020. (Accepted).</span></p><p class="c20"><span>[3]</span><span class="c36">&nbsp; &nbsp;</span><span class="c2">Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, Massimo Tornatore, and Stefano Secci, &ldquo;Intelligent reflecting surface assisted anti-jamming communications based on reinforcement learning&rdquo; IEEE Global Communications Conference (GLOBECOM), Taipei, Taiwan, Dec. 2020. (Accepted).</span></p><p class="c20"><span>[4]</span><span class="c36">&nbsp;</span><span>Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Qingqing Wu, and H. Vincent Poor, &ldquo;Intelligent reflecting surface assisted anti-jamming communications: A fast reinforcement learning approach,&rdquo; IEEE Transactions on Wireless Communications. (Major revision)</span><span><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/2004.12539&amp;sa=D&amp;ust=1602411110613000&amp;usg=AOvVaw07UQqLW_08Uodo0YEKW4su">&nbsp;</a></span><span class="c42"><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/2004.12539&amp;sa=D&amp;ust=1602411110614000&amp;usg=AOvVaw1Z-gSi9WtHqu7pKy9wQoJZ">https://arxiv.org/abs/2004.12539</a></span><span class="c2">.</span></p><p class="c64"><span class="c2">&nbsp;</span></p><h2 class="c33 c50" id="h.lszw2wedak7e"><span class="c10">4.2 </span><span>Artificial Intelligence-Enabled Intelligent 6G Networks </span></h2><p class="c11"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In order to support near-instant and seamless super-connectivity, an integrated space&ndash;air&ndash;ground&ndash;underwater network (ISAGUN) will be the core potential architecture of 6G networks, as shown in Fig. 7, where ISAGUN mainly consists of the following four tiers:</span></p><p class="c56"><span class="c38">&middot;</span><span class="c36">&nbsp; &nbsp; </span><span class="c2">Space-network tier deploys low Earth orbit, medium Earth orbit, and geostationary Earth orbit satellites to provide orbit or space services for unserved areas which are not covered by ground networks.</span></p><p class="c56"><span class="c38">&middot;</span><span class="c36">&nbsp; &nbsp; </span><span class="c2">Air-network tier employs various aerial platforms including unmanned aerial vehicles (UAVs), airships, and balloons associated with flying base stations (BSs) to support flexible and reliable wireless connectivity for remote areas or urgent events.</span></p><p class="c56"><span class="c38">&middot;</span><span class="c36">&nbsp; &nbsp; </span><span class="c2">Ground-network tier is the main solution for supporting diverse services for a massive number of devices. In order to satisfy various services, this layer mainly exploits low-frequency, microwave, mmWave, visible light and Terahertz (THz) bands for 6G networks.</span></p><p class="c56"><span class="c38">&middot;</span><span class="c36">&nbsp; &nbsp; </span><span class="c2">Underwater-network tier aims to provide underwater communication connectivity, observation and monitoring services for broad-sea and deep-sea activities.</span></p><p class="c11"><span>&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 598.00px; height: 427.00px;"><img alt="" src="images/image32.png" style="width: 598.00px; height: 427.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c11"><span class="c1">Fig.7. The typical architecture of 6G network (ISAGUN). V2X: vehicle to everything; VLC: visible light communication; RAN: radio access networks; SDN: software-defined networking; NFV: network function virtualization; PHY: physical layer; MAC: medium access control.</span></p><p class="c11"><span class="c2">&nbsp;</span></p><p class="c11 c62"><span class="c2">The development of 6G networks will be large-scale, multi-layered, high complex, dynamic, and heterogeneous. In addition, 6G networks need to support seamless connectivity and guarantee diverse QoS requirements of the huge number of devices, as well as process large amounts of data generated from physical environments. AI techniques with powerful analysis ability, learning ability, optimizing ability and intelligent recognition ability, which can be employed into 6G networks to intelligently carry out performance optimization, knowledge discovery, sophisticated learning, structure organization and complicated decision making. With the help of AI, we present an AI-enabled intelligent architecture for 6G networks which is mainly divided into four layers: intelligent sensing layer, data mining and analytics layer, intelligent control layer and smart application layer, as shown in Fig. 8. This four-layer bottom-up architecture can clearly serve as a transparent bridge between the physical world (with general physical/virtual things, objects, resources, etc.) and social world (with human demand, social behavior, etc.).</span></p><p class="c11 c62"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 402.00px;"><img alt="" src="images/image13.png" style="width: 624.00px; height: 402.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c11"><span class="c1">Fig. 8. The architecture of AI-enabled intelligent 6G networks.</span></p><p class="c11"><span class="c2">&nbsp;</span></p><p class="c6"><span class="c2">&nbsp; &nbsp;In 5G and B5G networks shown in Fig. 9, massive communication links aim to access the limited radio spectrum, which can be modelled as a multi-agent RL problem, where each communication link is regarded as a learning agent to interact with network environment to learn its experience, and the learned experience is then utilized to optimize its own spectrum access strategy. Massive agents explore the outside network environment and search spectrum access and power control strategies according to the observations of the network state. </span></p><p class="c6"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 421.00px; height: 281.00px;"><img alt="" src="images/image7.png" style="width: 421.00px; height: 281.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c6"><span class="c1">Fig. 9. DQN training based intelligent subchannel assignment and power control for massive access.</span></p><p class="c6"><span class="c2">&nbsp;</span></p><p class="c6"><span>&nbsp; &nbsp; Fig. 10 depicts the EE performance and the transmission success probability with varying number of devices when the packet arrival rate is 0.03 packets/slot/per communication link, the reliability and latency thresholds are 99.999% and 5ms, respectively. Note: Transmission success probability is the sum probability of the satisfied URLLC probability and the satisfied minimum data rate probability. From Fig. 10, we can observe that the performance of the four approaches decreases as the increased number of devices increases. As more devices lead to more communication links, all links attempt to access the limited spectrum radio which increases co-channel interference, and more devices consume the more energy, hence the EE performance decreases in this case as shown in Fig. 10 (a). At the same time, from Fig. 10 (b), we find that the transmission success probability can be maintained at a good level when the number of devices is moderate (less than 1800), but it declines significantly once the number of devices increases beyond an acceptable margin. Such the phenomenon has the following reasons: the serious co-channel interference decreases the channel quality; the massive number of communication links require to be served and various QoS requirements need to be satisfied, all approaches cannot complete all the massive number of services under the limited spectrum resource, thereby leading to the decease of the probability of the transmission success links. </span><span class="c2 c37">&nbsp;</span></p><p class="c11"><span class="c37">&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 285.00px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 285.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c11"><span class="c1">Fig. 10. Performance comparisons with different total numbers of devices.</span></p><p class="c11"><span class="c2">&nbsp;</span></p><p class="c11"><span class="c2">&nbsp;</span></p><p class="c11"><span class="c2">&nbsp;</span></p><p class="c20"><span>[5]</span><span class="c36">&nbsp;</span><span>Helin Yang, Arokiaswami Alphones, Zehui Xiong, Dusit Niyato, and Jun Zhao, &ldquo;Artificial intelligence-enabled intelligent 6G networks&rdquo;, IEEE Network. (Accepted)</span><span class="c60">&nbsp;</span><span class="c2">DOI: &nbsp;10.1109/MNET.011.2000195.</span></p><p class="c20"><span>[6]</span><span class="c36">&nbsp;</span><span>Helin Yang, Zehui Xiong, Jun Zhao, Dusit Niyato, Chau Yuen, and Ruilong Deng, &ldquo;Deep reinforcement learning based massive access management for ultra-reliable low-latency communications,&rdquo; IEEE Transactions on Wireless Communications. (Major revision).</span><span><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/2002.08743&amp;sa=D&amp;ust=1602411110616000&amp;usg=AOvVaw3hKYw2O12AMJy-FQUelIAu">&nbsp;</a></span><span class="c42"><a class="c18" href="https://www.google.com/url?q=https://arxiv.org/abs/2002.08743&amp;sa=D&amp;ust=1602411110616000&amp;usg=AOvVaw3hKYw2O12AMJy-FQUelIAu">https://arxiv.org/abs/ 2002.08743</a></span><span class="c2">.</span></p><p class="c20 c19 c59"><span class="c2"></span></p><h2 class="c44 c33" id="h.t4stu62ef8nq"><span class="c10">4.3 </span><span class="c10 c51">Privacy-Preserving Federated Learning for Wireless Networks</span></h2><p class="c31"><span>See </span><span class="c17"><a class="c18" href="#h.k5hj3xhgheo6">1.6.2 Privacy-Preserving Federated Learning for Wireless Networks</a></span></p><h3 class="c44 c33 c45" id="h.s5qernuuhlcj"><span class="c4"></span></h3><p class="c20"><span>&nbsp; </span></p></body></html>
